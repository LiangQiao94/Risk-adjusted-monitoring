{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50887765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f669b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import _pickle as cPickle\n",
    "\n",
    "def save_zipped_pickle(obj, filename, protocol=-1):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        cPickle.dump(obj, f, protocol)\n",
    "        \n",
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = cPickle.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb1602",
   "metadata": {},
   "source": [
    "## Data reading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50765a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100181"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data (reviews for model training and validation)\n",
    "data_whole = pd.read_csv('./corpus/data_whole.csv',index_col = 0,na_filter=False)\n",
    "len(data_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1edbc609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.sentiment.util import mark_negation\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stopset = stopwords.words('english') + ['will', 'also', 'said']\n",
    "del_str = string.punctuation + string.digits\n",
    "replace = str.maketrans(del_str,' '*len(del_str))\n",
    "\n",
    "docs = []\n",
    "for review_text in data_whole['review/text']: \n",
    "    sentences = nltk.sent_tokenize(review_text)\n",
    "    review_doc = []\n",
    "    for doc in sentences:\n",
    "        doc = doc.encode(\"utf8\").decode(\"utf8\").encode('ascii', 'ignore').decode() # ignore fancy unicode chars  \n",
    "        doc = doc.lower()\n",
    "        doc = doc.replace(\"don't\",\"do not\").replace(\"dn't\",\"d not\").replace(\"sn't\",\"s not\").replace(\"ren't\",\"re not\").replace(\"won't\",\"will not\")\n",
    "        doc = doc.translate(replace)\n",
    "        doc = nltk.word_tokenize(doc)        \n",
    "        # perform negation\n",
    "        if \"not\" in doc:\n",
    "            neg_idx = doc.index(\"not\")\n",
    "            pos_tags = nltk.pos_tag(doc)\n",
    "            for idx in range(neg_idx+1,len(doc)):\n",
    "                if pos_tags[idx][1] in [\"JJ\",\"JJR\",\"JJS\",\"RB\",\"RBR\",\"RBS\",\"VB\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"] or doc[idx]==\"like\":\n",
    "                    doc[idx] = \"neg_\" + doc[idx]\n",
    "        doc = [w for w in doc if w not in stopset]\n",
    "        doc = [stemmer.stem(w) for w in doc]\n",
    "        review_doc += doc\n",
    "    docs.append(review_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72ab046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\liang\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\requests\\__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "c:\\users\\liang\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\paramiko\\transport.py:32: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\n",
      "  from cryptography.hazmat.backends import default_backend\n"
     ]
    }
   ],
   "source": [
    "# build dictionary\n",
    "import gensim\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "dictionary.filter_extremes(no_below=60, no_above=0.5)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9e4e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3025"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary) # number of unique tokens in dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdae7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary for future use\n",
    "dictionary.save(\"./corpus/negation_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f3d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack into corpus\n",
    "corpus = []\n",
    "for doc in docs:\n",
    "    packed_doc = [dictionary.token2id[word] for word in doc if word in dictionary.token2id.keys()]\n",
    "    corpus.append(packed_doc)\n",
    "    \n",
    "data_whole['review_bow'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eca99be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_whole.to_csv('./corpus/data_whole.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7419e",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1f4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "\n",
    "# Jan and Feb 2010 as training set \n",
    "trainset = data_whole[data_whole['month'].isin([1,2])]\n",
    "train_set = trainset[['review/profileName','beer/beerId','review/overall','review_bow']].copy()\n",
    "train_set.columns = ['user','item','rating','review']\n",
    "train_set = Dataset(corpus=train_set,vocab=dictionary)\n",
    "# Mar 2010 as validation set\n",
    "valset = data_whole[data_whole['month'].isin([3])]\n",
    "val_set = valset[['review/profileName','beer/beerId','review/overall','review_bow']].copy()\n",
    "val_set.columns = ['user','item','rating','review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92fbc8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66285, 33896)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset),len(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d08e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model construction\n",
    "from Model_c import Model\n",
    "model = Model(train_set, K=5, reg=0.01, alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "668486b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.217817002338386"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg length of review\n",
    "model.W_D/model.D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "136363fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic seed words\n",
    "seed_words = []\n",
    "appearance_w = [dictionary.token2id[word] for word in ['color', 'white','dark', 'brown','look','amber','glass','finger','orang','golden','floral']]\n",
    "seed_words.append(appearance_w)\n",
    "aroma_w = [dictionary.token2id[word] for word in ['smell', 'nose', 'citru', 'hint']]\n",
    "seed_words.append(aroma_w)\n",
    "palate_w = [dictionary.token2id[word] for word in ['carbon', 'bodi', 'mouthfeel', 'medium','palat', 'smooth','creami', 'feel', 'full', 'dri', 'mouth','thin','crisp', 'thick']]\n",
    "seed_words.append(palate_w)\n",
    "taste_w = [dictionary.token2id[word] for word in ['tast', 'flavor','aftertast', 'balanc']]\n",
    "seed_words.append(taste_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03df28fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initialization with topic seed words\n",
    "# the topic seed words are only assigned with respective topics in initialization\n",
    "for d, i, j, r, doc in model.trainset.all_reviews():\n",
    "    for n in range(len(doc)):\n",
    "        w = doc[n]\n",
    "        for k in range(len(seed_words)):\n",
    "            if w in seed_words[k]:\n",
    "                model.gamma[d][n] = np.zeros(model.K*2)\n",
    "                model.gamma[d][n][k] = 0.5\n",
    "                model.gamma[d][n][k+model.K] = 0.5\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f59ff208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for re-initialize with different normal distributions\n",
    "def re_initialize(model,mu=0,sigma=0.1,seed=0):\n",
    "    np.random.seed(seed)\n",
    "    model.U = np.abs(np.random.normal(mu,sigma,size=(model.I,model.K)))     # user factor matrix\n",
    "    model.V = np.random.normal(mu,sigma,size=(model.J,model.K))     # item factor matrix\n",
    "    model.b_i = np.random.normal(mu,sigma,size=model.I)             # user bias vector\n",
    "    model.b_j = np.random.normal(mu,sigma,size=model.J)             # item bias vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44d9b7",
   "metadata": {},
   "source": [
    "### Inference of standard latent factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b5ce739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, test MSE = 8.772720940277132\n",
      "Epoch 1, test MSE = 8.146347076118925\n",
      "Epoch 2, test MSE = 7.722494396330388\n",
      "Epoch 3, test MSE = 7.410043748911569\n",
      "Epoch 4, test MSE = 7.1675784981735395\n",
      "Epoch 5, test MSE = 6.97288033937749\n",
      "Epoch 6, test MSE = 6.812578514288986\n",
      "Epoch 7, test MSE = 6.67798219860783\n",
      "Epoch 8, test MSE = 6.563131457051299\n",
      "Epoch 9, test MSE = 6.4637678695182474\n",
      "Epoch 10, test MSE = 6.376745726856462\n",
      "Epoch 11, test MSE = 6.299696631967746\n",
      "Epoch 12, test MSE = 6.230806770469381\n",
      "Epoch 13, test MSE = 6.1687203112535665\n",
      "Epoch 14, test MSE = 6.112457685636446\n",
      "Epoch 15, test MSE = 6.061267338082786\n",
      "Epoch 16, test MSE = 6.014602776403905\n",
      "Epoch 17, test MSE = 5.972102933013146\n",
      "Epoch 18, test MSE = 5.933533066666943\n",
      "Epoch 19, test MSE = 5.898694512985236\n",
      "Epoch 20, test MSE = 5.867336431177215\n",
      "Epoch 21, test MSE = 5.839179139162204\n",
      "Epoch 22, test MSE = 5.8139735186789645\n",
      "Epoch 23, test MSE = 5.791517080217391\n",
      "Epoch 24, test MSE = 5.771651002102766\n",
      "Epoch 25, test MSE = 5.754241325415029\n",
      "Epoch 26, test MSE = 5.7391614052811235\n",
      "Epoch 27, test MSE = 5.726268409491985\n",
      "Epoch 28, test MSE = 5.715370866293433\n",
      "Epoch 29, test MSE = 5.706274311848171\n",
      "Epoch 30, test MSE = 5.698801407022017\n",
      "Epoch 31, test MSE = 5.692803780171567\n",
      "Epoch 32, test MSE = 5.688108983016767\n",
      "Epoch 33, test MSE = 5.684529301645602\n",
      "Epoch 34, test MSE = 5.681930358380527\n",
      "Epoch 35, test MSE = 5.6802261860086105\n",
      "Epoch 36, test MSE = 5.679376012289634\n",
      "Epoch 37, test MSE = 5.679232751804934\n"
     ]
    }
   ],
   "source": [
    "# model inference of latent factor model using ratings only\n",
    "model.reg = 0.06 # regularization parameter\n",
    "re_initialize(model,mu=0,sigma=0.01,seed=0)\n",
    "model.RatingMF_SGD(lr_sgd = 0.005, test_set = val_set, threshold=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2a99872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for future use\n",
    "save_zipped_pickle(model, './models/RatingMF_reg' + str(model.reg) + '.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8866f76",
   "metadata": {},
   "source": [
    "### Inference of United latent factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e384a81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, test MSE = 8.765308382545589\n",
      "Epoch 1, test MSE = 8.129725400265187\n",
      "Epoch 2, test MSE = 7.699392689510695\n",
      "Epoch 3, test MSE = 7.381569211838095\n",
      "Epoch 4, test MSE = 7.134202411318783\n",
      "Epoch 5, test MSE = 6.9349198963846765\n",
      "Epoch 6, test MSE = 6.7703150622845625\n",
      "Epoch 7, test MSE = 6.631659132772679\n",
      "Epoch 8, test MSE = 6.512927108782794\n",
      "Epoch 9, test MSE = 6.40976572872157\n",
      "Epoch 10, test MSE = 6.31891200513507\n",
      "Epoch 11, test MSE = 6.237885970542073\n",
      "Epoch 12, test MSE = 6.164803380295824\n",
      "Epoch 13, test MSE = 6.098420682773966\n",
      "Epoch 14, test MSE = 6.03804269162232\n",
      "Epoch 15, test MSE = 5.983383131082658\n",
      "Epoch 16, test MSE = 5.93425339089631\n",
      "Epoch 17, test MSE = 5.890234225978135\n",
      "Epoch 18, test MSE = 5.850730236715048\n",
      "Epoch 19, test MSE = 5.8152229403618945\n",
      "Epoch 20, test MSE = 5.783370768849482\n",
      "Epoch 21, test MSE = 5.754944226395279\n",
      "Epoch 22, test MSE = 5.729759750258205\n",
      "Epoch 23, test MSE = 5.707635820023223\n",
      "Epoch 24, test MSE = 5.688366090635322\n",
      "Epoch 25, test MSE = 5.671750956874268\n",
      "Epoch 26, test MSE = 5.65759205433799\n",
      "Epoch 27, test MSE = 5.645690810157662\n",
      "Epoch 28, test MSE = 5.635866471732135\n",
      "Epoch 29, test MSE = 5.627966877367773\n",
      "Epoch 30, test MSE = 5.621749887228086\n",
      "Epoch 31, test MSE = 5.617002944142821\n",
      "Epoch 32, test MSE = 5.613616435709515\n",
      "Epoch 33, test MSE = 5.6114959281562\n",
      "Epoch 34, test MSE = 5.610542854298165\n",
      "Epoch 35, test MSE = 5.6107113562868625\n"
     ]
    }
   ],
   "source": [
    "# model inference of latent factor model using both ratings and reviews\n",
    "model.reg=0.01\n",
    "model.alpha = 0.01\n",
    "re_initialize(model,mu=0,sigma=0.01,seed=0)\n",
    "model.UnitedMF_SGD(lr_sgd = 0.005, test_set = val_set, threshold=0.0001, update_kappa=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71d0a613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2803894895110526"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "effdecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for future use\n",
    "save_zipped_pickle(model, './models/UnitedMF_reg' + str(model.reg) + '_alpha' + str(model.alpha) + '.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d80adf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6107113562868625\n"
     ]
    }
   ],
   "source": [
    "# prediction errors\n",
    "rating_loss = 0\n",
    "errors = []\n",
    "for index, row in val_set.iterrows():\n",
    "    j = row['item']\n",
    "    r = row['rating']\n",
    "    i = row['user']\n",
    "    r_hat = model.predict_rating(i,j)\n",
    "    rating_loss += (r_hat-r)**2\n",
    "    errors.append(r - r_hat)\n",
    "print(rating_loss/len(val_set)) # MSE on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e380a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5914608965313294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.9000e+01, 5.2000e+01, 9.2000e+01, 2.0500e+02, 4.7700e+02,\n",
       "        1.1430e+03, 3.2510e+03, 9.8060e+03, 1.2666e+04, 4.9810e+03,\n",
       "        9.9000e+02, 1.8200e+02, 1.7000e+01, 1.2000e+01, 3.0000e+00]),\n",
       " array([-15.20665567, -13.38471314, -11.56277061,  -9.74082808,\n",
       "         -7.91888555,  -6.09694303,  -4.2750005 ,  -2.45305797,\n",
       "         -0.63111544,   1.19082709,   3.01276961,   4.83471214,\n",
       "          6.65665467,   8.4785972 ,  10.30053973,  12.12248225]),\n",
       " <BarContainer object of 15 artists>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAARN0lEQVR4nO3df6zddX3H8edr7cAfUwG561jLdrvYuYDZFBtgcTNONlrAWFyUQMzstFlnBpv7kWiZf3QBWcp+MXWC6aSzGEdtmI5GUOwQR5aMHxchSEHGlR/SptArBdzGRIvv/XE+dYfu3rb3nNN77m2fj+TmfL/v7+f7Pe9vTnpf9/vjfJuqQpJ0ZPuxYTcgSRo+w0CSZBhIkgwDSRKGgSQJmD/sBnp1/PHH1+jo6LDbkKQ55a677vpOVY3sW5+zYTA6OsrY2Niw25CkOSXJY5PVPU0kSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiTm8DeQpbludM0NA9/mo+vOGfg2dWTwyECSZBhIkgwDSRKGgSQJw0CShGEgSeIgwiDJhiS7ktzXVfvLJN9Mcm+SLyQ5pmvZxUnGkzyYZFlXfXmrjSdZ01VfnOT2Vv9ckqMGuH+SpINwMEcGnwaW71PbCryuqn4R+A/gYoAkJwHnAye3da5MMi/JPOATwFnAScAFbSzA5cAVVfUa4GlgVV97JEmatgOGQVXdCuzep/aVqtrTZm8DFrXpFcCmqnq+qh4BxoFT2894VT1cVd8HNgErkgR4K3BdW38jcG5/uyRJmq5BXDN4H/ClNr0QeLxr2fZWm6r+auCZrmDZW5ckzaC+wiDJh4E9wGcH084B3291krEkYxMTEzPxlpJ0ROg5DJL8NvA24N1VVa28Azixa9iiVpuq/hRwTJL5+9QnVVXrq2ppVS0dGRnptXVJ0j56CoMky4EPAm+vque6Fm0Bzk9ydJLFwBLgDuBOYEm7c+goOheZt7QQuQV4Z1t/JXB9b7siSerVwdxaei3w78Brk2xPsgr4O+AVwNYk9yT5JEBVbQM2A/cDXwYurKoX2jWBi4CbgAeAzW0swIeAP04yTucawtUD3UNJ0gEd8BHWVXXBJOUpf2FX1WXAZZPUbwRunKT+MJ27jSRJQ+I3kCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJImDCIMkG5LsSnJfV+24JFuTPNRej231JPlYkvEk9yY5pWudlW38Q0lWdtXfmOQbbZ2PJcmgd1KStH8Hc2TwaWD5PrU1wM1VtQS4uc0DnAUsaT+rgaugEx7AWuA04FRg7d4AaWN+p2u9fd9LknSIHTAMqupWYPc+5RXAxja9ETi3q35NddwGHJPkBGAZsLWqdlfV08BWYHlb9sqquq2qCrima1uSpBnS6zWDBVW1s00/ASxo0wuBx7vGbW+1/dW3T1KfVJLVScaSjE1MTPTYuiRpX31fQG5/0dcAejmY91pfVUuraunIyMhMvKUkHRF6DYMn2yke2uuuVt8BnNg1blGr7a++aJK6JGkGze9xvS3ASmBde72+q35Rkk10LhY/W1U7k9wE/HnXReMzgYuraneS7yY5HbgdeA/w8R57kg6p0TU3DLsF6ZA5YBgkuRZ4C3B8ku107gpaB2xOsgp4DDivDb8ROBsYB54D3gvQfulfCtzZxl1SVXsvSv8enTuWXgp8qf1IkmbQAcOgqi6YYtEZk4wt4MIptrMB2DBJfQx43YH6kCQdOn4DWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkugzDJL8UZJtSe5Lcm2SlyRZnOT2JONJPpfkqDb26DY/3paPdm3n4lZ/MMmyPvdJkjRNPYdBkoXAHwBLq+p1wDzgfOBy4Iqqeg3wNLCqrbIKeLrVr2jjSHJSW+9kYDlwZZJ5vfYlSZq+fk8TzQdemmQ+8DJgJ/BW4Lq2fCNwbpte0eZpy89IklbfVFXPV9UjwDhwap99SZKmoecwqKodwF8B36YTAs8CdwHPVNWeNmw7sLBNLwQeb+vuaeNf3V2fZJ0XSbI6yViSsYmJiV5blyTto5/TRMfS+at+MfDTwMvpnOY5ZKpqfVUtraqlIyMjh/KtJOmI0s9pol8HHqmqiar6AfB54E3AMe20EcAiYEeb3gGcCNCWvwp4qrs+yTqSpBnQTxh8Gzg9ycvauf8zgPuBW4B3tjErgevb9JY2T1v+1aqqVj+/3W20GFgC3NFHX5KkaZp/4CGTq6rbk1wHfB3YA9wNrAduADYl+UirXd1WuRr4TJJxYDedO4ioqm1JNtMJkj3AhVX1Qq99SZKmr+cwAKiqtcDafcoPM8ndQFX1PeBdU2znMuCyfnqRJPXObyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSfYZBkmOSXJfkm0keSPLLSY5LsjXJQ+312DY2ST6WZDzJvUlO6drOyjb+oSQr+90pSdL09Htk8FHgy1X1C8AvAQ8Aa4Cbq2oJcHObBzgLWNJ+VgNXASQ5DlgLnAacCqzdGyCSpJnRcxgkeRXwZuBqgKr6flU9A6wANrZhG4Fz2/QK4JrquA04JskJwDJga1Xtrqqnga3A8l77kiRNXz9HBouBCeAfktyd5FNJXg4sqKqdbcwTwII2vRB4vGv97a02Vf3/SbI6yViSsYmJiT5alyR16ycM5gOnAFdV1RuA/+b/TgkBUFUFVB/v8SJVtb6qllbV0pGRkUFtVpKOeP2EwXZge1Xd3uavoxMOT7bTP7TXXW35DuDErvUXtdpUdUnSDOk5DKrqCeDxJK9tpTOA+4EtwN47glYC17fpLcB72l1FpwPPttNJNwFnJjm2XTg+s9UkSTNkfp/r/z7w2SRHAQ8D76UTMJuTrAIeA85rY28EzgbGgefaWKpqd5JLgTvbuEuqaneffUmSpqGvMKiqe4Clkyw6Y5KxBVw4xXY2ABv66UWS1Du/gSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRL9P5tI0iwyuuaGgW7v0XXnDHR7mr08MpAkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYgBhkGRekruTfLHNL05ye5LxJJ9LclSrH93mx9vy0a5tXNzqDyZZ1m9PkqTpGcSRwQeAB7rmLweuqKrXAE8Dq1p9FfB0q1/RxpHkJOB84GRgOXBlknkD6EuSdJD6CoMki4BzgE+1+QBvBa5rQzYC57bpFW2etvyMNn4FsKmqnq+qR4Bx4NR++pIkTU+/RwZ/C3wQ+GGbfzXwTFXtafPbgYVteiHwOEBb/mwb/6P6JOu8SJLVScaSjE1MTPTZuiRpr57DIMnbgF1VddcA+9mvqlpfVUuraunIyMhMva0kHfb6+Z/O3gS8PcnZwEuAVwIfBY5JMr/99b8I2NHG7wBOBLYnmQ+8Cniqq75X9zqSpBnQ85FBVV1cVYuqapTOBeCvVtW7gVuAd7ZhK4Hr2/SWNk9b/tWqqlY/v91ttBhYAtzRa1+SpOk7FP8H8oeATUk+AtwNXN3qVwOfSTIO7KYTIFTVtiSbgfuBPcCFVfXCIehLkjSFgYRBVX0N+FqbfphJ7gaqqu8B75pi/cuAywbRiyRp+vwGsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgSeLQfOlMmhVG19ww7BakOcMjA0mSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJoo8wSHJikluS3J9kW5IPtPpxSbYmeai9HtvqSfKxJONJ7k1ySte2VrbxDyVZ2f9uSZKmo58jgz3An1TVScDpwIVJTgLWADdX1RLg5jYPcBawpP2sBq6CTngAa4HTgFOBtXsDRJI0M3oOg6raWVVfb9P/CTwALARWABvbsI3AuW16BXBNddwGHJPkBGAZsLWqdlfV08BWYHmvfUmSpm8g1wySjAJvAG4HFlTVzrboCWBBm14IPN612vZWm6o+2fusTjKWZGxiYmIQrUuSGEAYJPkJ4J+AP6yq73Yvq6oCqt/36Nre+qpaWlVLR0ZGBrVZSTri9RUGSX6cThB8tqo+38pPttM/tNddrb4DOLFr9UWtNlVdkjRD+rmbKMDVwANV9Tddi7YAe+8IWglc31V/T7ur6HTg2XY66SbgzCTHtgvHZ7aaJGmGzO9j3TcBvwV8I8k9rfanwDpgc5JVwGPAeW3ZjcDZwDjwHPBegKraneRS4M427pKq2t1HX5Kkaeo5DKrq34BMsfiMScYXcOEU29oAbOi1F0lSf/wGsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCTR3zeQpYEZXXPDsFuQjmgeGUiSDANJkqeJJO3HoE/fPbrunIFuT4PjkYEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnC7xmoRz4+Qjq8eGQgSTIMJEmGgSQJrxkcMTzHL2l/Zk0YJFkOfBSYB3yqqtYNuSVJA+aD72avWREGSeYBnwB+A9gO3JlkS1XdP9zOhsO/4iXNtFkRBsCpwHhVPQyQZBOwAjgkYeAvW0l6sdkSBguBx7vmtwOn7TsoyWpgdZv9ryQP9vm+xwPf6XMbs5n7N3cdzvsGA9q/XD6ATg6N2fz5/exkxdkSBgelqtYD6we1vSRjVbV0UNubbdy/uetw3jdw/2aj2XJr6Q7gxK75Ra0mSZoBsyUM7gSWJFmc5CjgfGDLkHuSpCPGrDhNVFV7klwE3ETn1tINVbVtBt56YKecZin3b+46nPcN3L9ZJ1U17B4kSUM2W04TSZKGyDCQJB2ZYZDkXUm2JflhkqVd9dEk/5PknvbzyWH22aup9q8tuzjJeJIHkywbVo+DkOTPkuzo+rzOHnZPg5Bkeft8xpOsGXY/g5bk0STfaJ/Z2LD76UeSDUl2Jbmvq3Zckq1JHmqvxw6zx4N1RIYBcB/wm8Ctkyz7VlW9vv28f4b7GpRJ9y/JSXTu1DoZWA5c2R4FMpdd0fV53TjsZvrV9WiWs4CTgAva53a4+bX2mc2pe/En8Wk6/5a6rQFurqolwM1tftY7IsOgqh6oqn6/vTxr7Wf/VgCbqur5qnoEGKfzKBDNHj96NEtVfR/Y+2gWzUJVdSuwe5/yCmBjm94InDuTPfXqiAyDA1ic5O4k/5rkV4fdzIBN9tiPhUPqZVAuSnJvO1yfE4fjB3A4fkb7KuArSe5qj5g53Cyoqp1t+glgwTCbOViz4nsGh0KSfwF+apJFH66q66dYbSfwM1X1VJI3Av+c5OSq+u4ha7RHPe7fnLO//QSuAi6l88vlUuCvgffNXHfq0a9U1Y4kPwlsTfLN9hf2YaeqKsmcuH//sA2Dqvr1HtZ5Hni+Td+V5FvAzwOz7iJXL/vHHHzsx8HuZ5K/B754iNuZCXPuM5quqtrRXncl+QKdU2OHUxg8meSEqtqZ5ARg17AbOhieJuqSZGTvBdUkPwcsAR4eblcDtQU4P8nRSRbT2b87htxTz9o/tL3eQefC+Vx3WD+aJcnLk7xi7zRwJofH59ZtC7CyTa8E5sSR+mF7ZLA/Sd4BfBwYAW5Ick9VLQPeDFyS5AfAD4H3V9W+F4dmvan2r6q2JdlM5/+J2ANcWFUvDLPXPv1FktfTOU30KPC7Q+1mAIb4aJaZsgD4QhLo/P75x6r68nBb6l2Sa4G3AMcn2Q6sBdYBm5OsAh4DzhtehwfPx1FIkjxNJEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgSQL+F8FCC9YzjHBdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of prediction errors\n",
    "print(np.mean(errors))\n",
    "plt.hist(errors,bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d066e",
   "metadata": {},
   "source": [
    "## Qualitative analysis of derived topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee63f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "# load existing model and dictionary\n",
    "model = load_zipped_pickle('./models/UnitedMF_reg0.01_alpha0.01.p')\n",
    "dictionary = Dictionary.load('./corpus/negation_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f03bd92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dark, brown, white, orang, amber, color, floral, pour, malt, nice, hop, sweet, golden, chocol, bitter, \n",
      "1 citru, nose, sweet, pour, malt, roast, finish, bottl, nice, chocol, bitter, hint, caramel, light, hop, \n",
      "2 bodi, medium, dri, carbon, smooth, creami, full, palat, hop, mouthfeel, thick, nice, pour, thin, malt, \n",
      "3 flavor, tast, balanc, malt, sweet, nice, hop, pour, beer, caramel, bitter, light, good, finish, bottl, \n",
      "4 malt, sweet, hop, nice, pour, caramel, finish, chocol, bottl, note, bitter, fruit, beer, roast, coffe, \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# produce top topic words in positive side\n",
    "for k in range(model.K):\n",
    "    pos = np.argsort(model.phi[k])[::-1]    \n",
    "    sorted_counts = model.phi[k][pos][:15]\n",
    "    sorted_vocab = [dictionary[idx] for idx in pos[:15]]\n",
    "    output = ''\n",
    "    for word, weight in zip(sorted_vocab, sorted_counts):\n",
    "        #output += '%s (%.3f), ' % (word, weight)\n",
    "        output += '%s, ' % word\n",
    "    print(k, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ceaedb7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 white, color, golden, amber, dark, brown, orang, pour, malt, light, sweet, beer, hop, bottl, floral, \n",
      "1 light, nose, hint, citru, sweet, bottl, clear, pour, beer, hop, malt, smell, finish, yellow, bitter, \n",
      "2 bodi, medium, carbon, thin, dri, palat, beer, malt, sweet, mouthfeel, light, hop, pour, creami, bottl, \n",
      "3 flavor, tast, light, sweet, beer, bottl, malt, hop, pour, balanc, finish, bitter, aftertast, malti, note, \n",
      "4 beer, malt, sweet, light, hop, bottl, pour, finish, note, bitter, like, bit, caramel, littl, clear, \n"
     ]
    }
   ],
   "source": [
    "# produce top topic words in negative side\n",
    "for k in range(model.K):\n",
    "    pos = np.argsort(model.phi[k+model.K])[::-1]    \n",
    "    sorted_counts = model.phi[k+model.K][pos][:15]\n",
    "    sorted_vocab = [dictionary[idx] for idx in pos[:15]]\n",
    "    output = ''\n",
    "    for word, weight in zip(sorted_vocab, sorted_counts):\n",
    "        #output += '%s (%.3f), ' % (word, weight)\n",
    "        output += '%s, ' % word\n",
    "    print(k, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
